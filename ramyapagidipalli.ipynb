{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "86RCCtkCSz32"
      },
      "outputs": [],
      "source": [
        "# ---------- 0. Imports ----------\n",
        "import os, warnings, numpy as np, pandas as pd\n",
        "import matplotlib.pyplot as plt, seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, RandomizedSearchCV\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import (f1_score, precision_score, recall_score,\n",
        "                             accuracy_score, confusion_matrix)\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, HistGradientBoostingClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from scipy.stats import randint, uniform\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "RANDOM_STATE = 42\n",
        "np.random.seed(RANDOM_STATE)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- 1. Load data ----------\n",
        "train = pd.read_csv(\"dataset_B_training.csv\")\n",
        "test  = pd.read_csv(\"dataset_B_testing.csv\")\n",
        "\n",
        "# ---------- 2. Basic EDA ----------\n",
        "print(\"Train:\", train.shape, \"Test:\", test.shape)\n",
        "print(train['h1n1_vaccine'].value_counts(normalize=True))\n",
        "\n",
        "sns.countplot(x='h1n1_vaccine', data=train)\n",
        "plt.title(\"Target Balance\"); plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559
        },
        "id": "Gkwar4LDWRdc",
        "outputId": "1c0b8fd9-b0b0-4dbb-eb62-7c907847c3e7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: (4756, 31) Test: (4749, 30)\n",
            "h1n1_vaccine\n",
            "0    0.605971\n",
            "1    0.394029\n",
            "Name: proportion, dtype: float64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- 3. Feature groups ----------\n",
        "cat_cols = ['age_group','education','race','sex','income_poverty','marital_status',\n",
        "            'rent_or_own','employment_status','census_msa','employment_sector']\n",
        "exclude = set(['respondent_id','h1n1_vaccine'] + cat_cols)\n",
        "num_cols = [c for c in train.columns if c not in exclude]\n"
      ],
      "metadata": {
        "id": "0_RMs-vta98D"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- 4. Split ----------\n",
        "X = train.drop(columns=['h1n1_vaccine'])\n",
        "y = train['h1n1_vaccine'].astype(int)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=RANDOM_STATE)"
      ],
      "metadata": {
        "id": "1VvO9ofwbJ3n"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- 5. Preprocessing ----------\n",
        "num_proc = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler(with_mean=False))\n",
        "])\n",
        "cat_proc = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('ohe', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "preprocess = ColumnTransformer([\n",
        "    ('num', num_proc, num_cols),\n",
        "    ('cat', cat_proc, cat_cols)\n",
        "])"
      ],
      "metadata": {
        "id": "A7rEYC_Qrb7r"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- 6. Models ----------\n",
        "models = {\n",
        "    \"logreg\": LogisticRegression(max_iter=2000, class_weight='balanced', random_state=RANDOM_STATE),\n",
        "    \"rf\": RandomForestClassifier(n_estimators=500, class_weight='balanced', random_state=RANDOM_STATE, n_jobs=-1),\n",
        "    \"hgb\": HistGradientBoostingClassifier(random_state=RANDOM_STATE),\n",
        "    \"extra\": ExtraTreesClassifier(n_estimators=600, class_weight='balanced', random_state=RANDOM_STATE, n_jobs=-1),\n",
        "    \"linsvc_cal\": CalibratedClassifierCV(\n",
        "        estimator=LinearSVC(class_weight='balanced', random_state=RANDOM_STATE),\n",
        "        method='sigmoid', cv=3)\n",
        "}\n",
        "pipes = {n: Pipeline([('prep', preprocess), ('clf', m)]) for n, m in models.items()}"
      ],
      "metadata": {
        "id": "E_E-C2oVriDj"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- 7. Helper: best threshold for F1 ----------\n",
        "def best_threshold_for_f1(y_true, scores):\n",
        "    x = scores\n",
        "    if x.min() < 0 or x.max() > 1:\n",
        "        x = (x - x.min()) / (x.max() - x.min() + 1e-9)\n",
        "    thresholds = np.linspace(0.05, 0.95, 19)\n",
        "    f1s = [f1_score(y_true, (x >= t).astype(int)) for t in thresholds]\n",
        "    t_best = thresholds[np.argmax(f1s)]\n",
        "    return float(t_best), float(max(f1s))\n",
        "\n",
        "def evaluate(name, pipe):\n",
        "    pipe.fit(X_train, y_train)\n",
        "    if hasattr(pipe['clf'], \"predict_proba\"):\n",
        "        scores = pipe.predict_proba(X_valid)[:,1]\n",
        "    elif hasattr(pipe['clf'], \"decision_function\"):\n",
        "        scores = pipe.decision_function(X_valid)\n",
        "    else:\n",
        "        scores = pipe.predict(X_valid)\n",
        "    thr, _ = best_threshold_for_f1(y_valid, scores)\n",
        "    y_pred = ( (scores - scores.min())/(scores.max()-scores.min()+1e-9) >= thr ).astype(int)\n",
        "    return {\n",
        "        \"name\": name,\n",
        "        \"threshold\": thr,\n",
        "        \"F1_valid\": f1_score(y_valid, y_pred),\n",
        "        \"precision\": precision_score(y_valid, y_pred, zero_division=0),\n",
        "        \"recall\": recall_score(y_valid, y_pred, zero_division=0),\n",
        "        \"accuracy\": accuracy_score(y_valid, y_pred)\n",
        "    }\n",
        "\n",
        "# ---------- 8. Train & evaluate all 5 ----------\n",
        "results = [evaluate(n,p) for n,p in pipes.items()]\n",
        "results_sorted = sorted(results, key=lambda r: r[\"F1_valid\"], reverse=True)\n",
        "\n",
        "# ---------- (A) Leaderboard ----------\n",
        "leaderboard = pd.DataFrame(results_sorted)\n",
        "print(\"\\n=== Leaderboard (validation) ===\")\n",
        "display(leaderboard.style.background_gradient(cmap='Blues'))\n",
        "\n",
        "# ---------- (B) Hyper-parameter tuning for top model ----------\n",
        "best_name = results_sorted[0]['name']\n",
        "print(\"\\nTuning top model:\", best_name)\n",
        "grid = {}\n",
        "\n",
        "if best_name == \"rf\" or best_name == \"extra\":\n",
        "    grid = {\n",
        "        \"clf__n_estimators\": randint(300, 1200),\n",
        "        \"clf__max_depth\": randint(4, 40),\n",
        "        \"clf__min_samples_split\": randint(2, 10),\n",
        "        \"clf__min_samples_leaf\": randint(1, 6)\n",
        "    }\n",
        "elif best_name == \"logreg\":\n",
        "    grid = {\n",
        "        \"clf__C\": uniform(0.01, 10.0),\n",
        "        \"clf__solver\": [\"lbfgs\", \"saga\"]\n",
        "    }\n",
        "elif best_name == \"hgb\":\n",
        "    grid = {\n",
        "        \"clf__max_depth\": randint(2, 20),\n",
        "        \"clf__learning_rate\": uniform(0.01, 0.3),\n",
        "        \"clf__l2_regularization\": uniform(0.0, 1.0)\n",
        "    }\n",
        "\n",
        "if grid:\n",
        "    tuned = RandomizedSearchCV(\n",
        "        estimator=pipes[best_name],\n",
        "        param_distributions=grid,\n",
        "        n_iter=25, scoring=\"f1\",\n",
        "        cv=3, random_state=RANDOM_STATE, n_jobs=-1, verbose=1\n",
        "    )\n",
        "    tuned.fit(X_train, y_train)\n",
        "    print(\"\\nBest CV-F1:\", tuned.best_score_)\n",
        "    print(\"Best parameters:\", tuned.best_params_)\n",
        "else:\n",
        "    print(\"No tuning grid defined for this model.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "QyPTRa_0rwiT",
        "outputId": "cece4966-ac10-4ec2-acad-b559586a4931"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Leaderboard (validation) ===\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7bd0018c3440>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_9b585_row0_col1, #T_9b585_row0_col2, #T_9b585_row0_col4, #T_9b585_row2_col1, #T_9b585_row2_col3, #T_9b585_row2_col5, #T_9b585_row4_col1 {\n",
              "  background-color: #08306b;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_9b585_row0_col3, #T_9b585_row0_col5, #T_9b585_row1_col1, #T_9b585_row2_col4, #T_9b585_row3_col1, #T_9b585_row4_col2, #T_9b585_row4_col4 {\n",
              "  background-color: #f7fbff;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_9b585_row1_col2 {\n",
              "  background-color: #4d99ca;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_9b585_row1_col3 {\n",
              "  background-color: #66abd4;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_9b585_row1_col4 {\n",
              "  background-color: #79b5d9;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_9b585_row1_col5 {\n",
              "  background-color: #539ecd;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_9b585_row2_col2 {\n",
              "  background-color: #ddeaf7;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_9b585_row3_col2 {\n",
              "  background-color: #ecf4fb;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_9b585_row3_col3 {\n",
              "  background-color: #1c6ab0;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_9b585_row3_col4 {\n",
              "  background-color: #e3eef9;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_9b585_row3_col5 {\n",
              "  background-color: #2b7bba;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_9b585_row4_col3 {\n",
              "  background-color: #08478d;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_9b585_row4_col5 {\n",
              "  background-color: #0b559f;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_9b585\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_9b585_level0_col0\" class=\"col_heading level0 col0\" >name</th>\n",
              "      <th id=\"T_9b585_level0_col1\" class=\"col_heading level0 col1\" >threshold</th>\n",
              "      <th id=\"T_9b585_level0_col2\" class=\"col_heading level0 col2\" >F1_valid</th>\n",
              "      <th id=\"T_9b585_level0_col3\" class=\"col_heading level0 col3\" >precision</th>\n",
              "      <th id=\"T_9b585_level0_col4\" class=\"col_heading level0 col4\" >recall</th>\n",
              "      <th id=\"T_9b585_level0_col5\" class=\"col_heading level0 col5\" >accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_9b585_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_9b585_row0_col0\" class=\"data row0 col0\" >logreg</td>\n",
              "      <td id=\"T_9b585_row0_col1\" class=\"data row0 col1\" >0.400000</td>\n",
              "      <td id=\"T_9b585_row0_col2\" class=\"data row0 col2\" >0.690286</td>\n",
              "      <td id=\"T_9b585_row0_col3\" class=\"data row0 col3\" >0.604000</td>\n",
              "      <td id=\"T_9b585_row0_col4\" class=\"data row0 col4\" >0.805333</td>\n",
              "      <td id=\"T_9b585_row0_col5\" class=\"data row0 col5\" >0.715336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9b585_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "      <td id=\"T_9b585_row1_col0\" class=\"data row1 col0\" >linsvc_cal</td>\n",
              "      <td id=\"T_9b585_row1_col1\" class=\"data row1 col1\" >0.350000</td>\n",
              "      <td id=\"T_9b585_row1_col2\" class=\"data row1 col2\" >0.685030</td>\n",
              "      <td id=\"T_9b585_row1_col3\" class=\"data row1 col3\" >0.621739</td>\n",
              "      <td id=\"T_9b585_row1_col4\" class=\"data row1 col4\" >0.762667</td>\n",
              "      <td id=\"T_9b585_row1_col5\" class=\"data row1 col5\" >0.723739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9b585_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "      <td id=\"T_9b585_row2_col0\" class=\"data row2 col0\" >rf</td>\n",
              "      <td id=\"T_9b585_row2_col1\" class=\"data row2 col1\" >0.400000</td>\n",
              "      <td id=\"T_9b585_row2_col2\" class=\"data row2 col2\" >0.679151</td>\n",
              "      <td id=\"T_9b585_row2_col3\" class=\"data row2 col3\" >0.638498</td>\n",
              "      <td id=\"T_9b585_row2_col4\" class=\"data row2 col4\" >0.725333</td>\n",
              "      <td id=\"T_9b585_row2_col5\" class=\"data row2 col5\" >0.730042</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9b585_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "      <td id=\"T_9b585_row3_col0\" class=\"data row3 col0\" >hgb</td>\n",
              "      <td id=\"T_9b585_row3_col1\" class=\"data row3 col1\" >0.350000</td>\n",
              "      <td id=\"T_9b585_row3_col2\" class=\"data row3 col2\" >0.678175</td>\n",
              "      <td id=\"T_9b585_row3_col3\" class=\"data row3 col3\" >0.630734</td>\n",
              "      <td id=\"T_9b585_row3_col4\" class=\"data row3 col4\" >0.733333</td>\n",
              "      <td id=\"T_9b585_row3_col5\" class=\"data row3 col5\" >0.725840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9b585_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "      <td id=\"T_9b585_row4_col0\" class=\"data row4 col0\" >extra</td>\n",
              "      <td id=\"T_9b585_row4_col1\" class=\"data row4 col1\" >0.400000</td>\n",
              "      <td id=\"T_9b585_row4_col2\" class=\"data row4 col2\" >0.677460</td>\n",
              "      <td id=\"T_9b585_row4_col3\" class=\"data row4 col3\" >0.635514</td>\n",
              "      <td id=\"T_9b585_row4_col4\" class=\"data row4 col4\" >0.725333</td>\n",
              "      <td id=\"T_9b585_row4_col5\" class=\"data row4 col5\" >0.727941</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Tuning top model: logreg\n",
            "Fitting 3 folds for each of 25 candidates, totalling 75 fits\n",
            "\n",
            "Best CV-F1: 0.7053884487231697\n",
            "Best parameters: {'clf__C': np.float64(3.0561376917337064), 'clf__solver': 'lbfgs'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- 9. Retrain top-5 on full data & export submissions ----------\n",
        "os.makedirs(\"submissions\", exist_ok=True)\n",
        "X_full, y_full = X, y\n",
        "\n",
        "for rank, r in enumerate(results_sorted[:5], start=1):\n",
        "    mname = r[\"name\"]\n",
        "    model = models[mname]\n",
        "    pipe = Pipeline([('prep', preprocess), ('clf', model)])\n",
        "    pipe.fit(X_full, y_full)\n",
        "\n",
        "    if hasattr(pipe['clf'], \"predict_proba\"):\n",
        "        s = pipe.predict_proba(test)[:,1]\n",
        "        y_pred = ( (s - s.min())/(s.max()-s.min()+1e-9) >= r[\"threshold\"] ).astype(int)\n",
        "    elif hasattr(pipe['clf'], \"decision_function\"):\n",
        "        d = pipe.decision_function(test)\n",
        "        y_pred = ( (d - d.min())/(d.max()-d.min()+1e-9) >= r[\"threshold\"] ).astype(int)\n",
        "    else:\n",
        "        y_pred = pipe.predict(test)\n",
        "\n",
        "    sub = pd.DataFrame({\"respondent_id\": test['respondent_id'], \"h1n1_vaccine\": y_pred})\n",
        "    fname = f\"challenge_submission_groupB_order{rank}_{mname}_F1_{r['F1_valid']:.4f}.csv\"\n",
        "    sub.to_csv(os.path.join(\"submissions\", fname), index=False)\n",
        "    print(\"Saved:\", fname)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpRiDs2Jr44T",
        "outputId": "080300fc-eaf4-4746-a88a-340d20e02cd0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: challenge_submission_groupB_order1_logreg_F1_0.6903.csv\n",
            "Saved: challenge_submission_groupB_order2_linsvc_cal_F1_0.6850.csv\n",
            "Saved: challenge_submission_groupB_order3_rf_F1_0.6792.csv\n",
            "Saved: challenge_submission_groupB_order4_hgb_F1_0.6782.csv\n",
            "Saved: challenge_submission_groupB_order5_extra_F1_0.6775.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- 10. Optional: CV check for top model ----------\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
        "cv_f1 = cross_val_score(pipes[best_name], X, y, scoring='f1', cv=cv, n_jobs=-1)\n",
        "print(f\"\\n{best_name} 5-fold CV-F1: {cv_f1.mean():.4f} ± {cv_f1.std():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkgd9En4sArj",
        "outputId": "2662a607-3770-4dc3-f632-317ee85e6e9e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "logreg 5-fold CV-F1: 0.7011 ± 0.0150\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 6. Define 10 models ---\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "models = {\n",
        "    # previous 5\n",
        "    \"logreg\": LogisticRegression(max_iter=2000, class_weight='balanced', random_state=RANDOM_STATE),\n",
        "    \"rf\": RandomForestClassifier(n_estimators=500, class_weight='balanced', random_state=RANDOM_STATE, n_jobs=-1),\n",
        "    \"hgb\": HistGradientBoostingClassifier(random_state=RANDOM_STATE),\n",
        "    \"extra\": ExtraTreesClassifier(n_estimators=600, class_weight='balanced', random_state=RANDOM_STATE, n_jobs=-1),\n",
        "    \"linsvc_cal\": CalibratedClassifierCV(\n",
        "        estimator=LinearSVC(class_weight='balanced', random_state=RANDOM_STATE),\n",
        "        method='sigmoid', cv=3\n",
        "    ),\n",
        "    # new 5\n",
        "    \"xgb\": XGBClassifier(\n",
        "        n_estimators=600, max_depth=6, learning_rate=0.05, subsample=0.9,\n",
        "        colsample_bytree=0.8, reg_lambda=1.0, objective=\"binary:logistic\",\n",
        "        eval_metric=\"logloss\", random_state=RANDOM_STATE, n_jobs=-1\n",
        "    ),\n",
        "    \"lgbm\": LGBMClassifier(\n",
        "        n_estimators=800, max_depth=-1, num_leaves=63, subsample=0.9,\n",
        "        colsample_bytree=0.8, learning_rate=0.05, class_weight='balanced',\n",
        "        random_state=RANDOM_STATE, n_jobs=-1\n",
        "    ),\n",
        "    \"cat\": CatBoostClassifier(\n",
        "        iterations=800, depth=6, learning_rate=0.05, l2_leaf_reg=3.0,\n",
        "        loss_function='Logloss', verbose=False, random_state=RANDOM_STATE, thread_count=-1\n",
        "    ),\n",
        "    \"gbc\": GradientBoostingClassifier(random_state=RANDOM_STATE),\n",
        "    \"dt\": DecisionTreeClassifier(max_depth=None, class_weight='balanced', random_state=RANDOM_STATE)\n",
        "}\n",
        "\n",
        "pipes = {name: Pipeline([('prep', preprocess), ('clf', model)]) for name, model in models.items()}\n",
        "\n",
        "# --- 7. F1 threshold tuning helper ---\n",
        "def best_threshold_for_f1(y_true, scores):\n",
        "    # scores can be probas or decision values; normalize if needed\n",
        "    s = scores.astype(float)\n",
        "    s_min, s_max = s.min(), s.max()\n",
        "    if (s_min < 0) or (s_max > 1):\n",
        "        s = (s - s_min) / (s_max - s_min + 1e-9)\n",
        "    thresholds = np.linspace(0.05, 0.95, 19)\n",
        "    f1s = []\n",
        "    for t in thresholds:\n",
        "        preds = (s >= t).astype(int)\n",
        "        f1s.append((t, f1_score(y_true, preds)))\n",
        "    t_best, f1_best = max(f1s, key=lambda z: z[1])\n",
        "    return float(t_best), float(f1_best)\n",
        "\n",
        "def evaluate_model(name, pipe):\n",
        "    pipe.fit(X_train, y_train)\n",
        "    if hasattr(pipe['clf'], \"predict_proba\"):\n",
        "        scores = pipe.predict_proba(X_valid)[:, 1]\n",
        "    elif hasattr(pipe['clf'], \"decision_function\"):\n",
        "        scores = pipe.decision_function(X_valid)\n",
        "    else:\n",
        "        # fallback hard predictions (rare here)\n",
        "        preds = pipe.predict(X_valid)\n",
        "        return {\n",
        "            \"name\": name,\n",
        "            \"threshold\": 0.5,\n",
        "            \"F1_valid\": f1_score(y_valid, preds),\n",
        "            \"precision\": precision_score(y_valid, preds, zero_division=0),\n",
        "            \"recall\": recall_score(y_valid, preds, zero_division=0),\n",
        "            \"accuracy\": accuracy_score(y_valid, preds)\n",
        "        }\n",
        "    thr, _ = best_threshold_for_f1(y_valid, scores)\n",
        "    s_min, s_max = scores.min(), scores.max()\n",
        "    s_norm = (scores - s_min) / (s_max - s_min + 1e-9)\n",
        "    y_pred = (s_norm >= thr).astype(int)\n",
        "    return {\n",
        "        \"name\": name,\n",
        "        \"threshold\": thr,\n",
        "        \"F1_valid\": f1_score(y_valid, y_pred),\n",
        "        \"precision\": precision_score(y_valid, y_pred, zero_division=0),\n",
        "        \"recall\": recall_score(y_valid, y_pred, zero_division=0),\n",
        "        \"accuracy\": accuracy_score(y_valid, y_pred)\n",
        "    }\n",
        "\n",
        "# --- 8. Train & evaluate all 10 models ---\n",
        "results = []\n",
        "for name, pipe in pipes.items():\n",
        "    print(f\"Training: {name}\")\n",
        "    res = evaluate_model(name, pipe)\n",
        "    results.append(res)\n",
        "    print(f\" -> F1={res['F1_valid']:.4f} | P={res['precision']:.4f} | R={res['recall']:.4f} | Acc={res['accuracy']:.4f}\")\n",
        "\n",
        "# Rank by F1\n",
        "results_sorted = sorted(results, key=lambda r: r[\"F1_valid\"], reverse=True)\n",
        "\n",
        "# --- (A) Leaderboard table ---\n",
        "leaderboard = pd.DataFrame(results_sorted)\n",
        "print(\"\\n=== Leaderboard (Validation) ===\")\n",
        "display(leaderboard.style.background_gradient(cmap='Blues'))\n",
        "\n",
        "# --- (B) Hyper-parameter tuning for the current #1 model ---\n",
        "from scipy.stats import randint, uniform\n",
        "\n",
        "best_name = results_sorted[0]['name']\n",
        "print(\"\\nTop model for tuning:\", best_name)\n",
        "\n",
        "tune_grid = {}\n",
        "if best_name == \"rf\" or best_name == \"extra\":\n",
        "    tune_grid = {\n",
        "        \"clf__n_estimators\": randint(400, 1400),\n",
        "        \"clf__max_depth\": randint(4, 40),\n",
        "        \"clf__min_samples_split\": randint(2, 12),\n",
        "        \"clf__min_samples_leaf\": randint(1, 6)\n",
        "    }\n",
        "elif best_name == \"logreg\":\n",
        "    tune_grid = {\n",
        "        \"clf__C\": uniform(0.01, 10.0),\n",
        "        \"clf__solver\": [\"lbfgs\", \"saga\"]\n",
        "    }\n",
        "elif best_name == \"hgb\":\n",
        "    tune_grid = {\n",
        "        \"clf__max_depth\": randint(3, 24),\n",
        "        \"clf__learning_rate\": uniform(0.01, 0.3),\n",
        "        \"clf__l2_regularization\": uniform(0.0, 1.0)\n",
        "    }\n",
        "elif best_name == \"xgb\":\n",
        "    tune_grid = {\n",
        "        \"clf__n_estimators\": randint(400, 1200),\n",
        "        \"clf__max_depth\": randint(3, 10),\n",
        "        \"clf__learning_rate\": uniform(0.01, 0.2),\n",
        "        \"clf__subsample\": uniform(0.6, 0.4),\n",
        "        \"clf__colsample_bytree\": uniform(0.6, 0.4),\n",
        "        \"clf__reg_lambda\": uniform(0.0, 2.0)\n",
        "    }\n",
        "elif best_name == \"lgbm\":\n",
        "    tune_grid = {\n",
        "        \"clf__n_estimators\": randint(400, 1400),\n",
        "        \"clf__num_leaves\": randint(31, 127),\n",
        "        \"clf__learning_rate\": uniform(0.01, 0.2),\n",
        "        \"clf__subsample\": uniform(0.6, 0.4),\n",
        "        \"clf__colsample_bytree\": uniform(0.6, 0.4)\n",
        "    }\n",
        "elif best_name == \"cat\":\n",
        "    tune_grid = {\n",
        "        \"clf__iterations\": randint(400, 1400),\n",
        "        \"clf__depth\": randint(4, 10),\n",
        "        \"clf__learning_rate\": uniform(0.01, 0.2),\n",
        "        \"clf__l2_leaf_reg\": uniform(1.0, 5.0)\n",
        "    }\n",
        "elif best_name == \"gbc\":\n",
        "    tune_grid = {\n",
        "        \"clf__n_estimators\": randint(200, 1000),\n",
        "        \"clf__learning_rate\": uniform(0.01, 0.2),\n",
        "        \"clf__max_depth\": randint(2, 8)\n",
        "    }\n",
        "elif best_name == \"dt\":\n",
        "    tune_grid = {\n",
        "        \"clf__max_depth\": randint(3, 40),\n",
        "        \"clf__min_samples_split\": randint(2, 20),\n",
        "        \"clf__min_samples_leaf\": randint(1, 10)\n",
        "    }\n",
        "elif best_name == \"linsvc_cal\":\n",
        "    tune_grid = {\n",
        "        \"clf__base_estimator__C\": uniform(0.1, 5.0)\n",
        "    }\n",
        "\n",
        "if tune_grid:\n",
        "    tuned = RandomizedSearchCV(\n",
        "        estimator=pipes[best_name],\n",
        "        param_distributions=tune_grid,\n",
        "        n_iter=30, scoring=\"f1\", cv=3,\n",
        "        random_state=RANDOM_STATE, n_jobs=-1, verbose=1\n",
        "    )\n",
        "    tuned.fit(X_train, y_train)\n",
        "    print(\"\\nBest CV-F1:\", tuned.best_score_)\n",
        "    print(\"Best params:\", tuned.best_params_)\n",
        "\n",
        "    # Evaluate tuned on validation with F1-threshold optimization\n",
        "    # (reuse evaluator by passing the already-fit estimator)\n",
        "    tuned_pipe = tuned.best_estimator_\n",
        "    if hasattr(tuned_pipe['clf'], \"predict_proba\"):\n",
        "        scr = tuned_pipe.predict_proba(X_valid)[:, 1]\n",
        "    elif hasattr(tuned_pipe['clf'], \"decision_function\"):\n",
        "        scr = tuned_pipe.decision_function(X_valid)\n",
        "    else:\n",
        "        scr = tuned_pipe.predict(X_valid)\n",
        "\n",
        "    thr_tuned, _ = best_threshold_for_f1(y_valid, scr)\n",
        "    s_min, s_max = scr.min(), scr.max()\n",
        "    s_norm = (scr - s_min) / (s_max - s_min + 1e-9)\n",
        "    preds_tuned = (s_norm >= thr_tuned).astype(int)\n",
        "    print(f\"Tuned {best_name}  -> F1_valid={f1_score(y_valid, preds_tuned):.4f}  thr={thr_tuned:.3f}\")\n",
        "else:\n",
        "    print(\"No tuning grid for the top model (skipped).\")\n",
        "\n",
        "# --- 9. Optional: 5-fold CV on the #1 model (sanity check) ---\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
        "cv_f1 = cross_val_score(pipes[best_name], X, y, scoring='f1', cv=cv, n_jobs=-1)\n",
        "print(f\"\\n{best_name} 5-fold CV-F1: {cv_f1.mean():.4f} ± {cv_f1.std():.4f}\")\n",
        "\n",
        "# --- 10. OPTIONAL submissions (only if test CSV is present) ---\n",
        "if test is not None:\n",
        "    os.makedirs(\"submissions\", exist_ok=True)\n",
        "    # retrain each of the top 5 on full training data, then predict test with tuned threshold from validation\n",
        "    for rank, r in enumerate(results_sorted[:5], start=1):\n",
        "        mname = r[\"name\"]\n",
        "        model = models[mname]\n",
        "        pipe = Pipeline([('prep', preprocess), ('clf', model)])\n",
        "        pipe.fit(X, y)\n",
        "\n",
        "        # get scores on test\n",
        "        if hasattr(pipe['clf'], \"predict_proba\"):\n",
        "            s = pipe.predict_proba(test)[:, 1]\n",
        "        elif hasattr(pipe['clf'], \"decision_function\"):\n",
        "            s = pipe.decision_function(test)\n",
        "        else:\n",
        "            # hard predictions\n",
        "            preds = pipe.predict(test).astype(int)\n",
        "            sub = pd.DataFrame({\"respondent_id\": test[\"respondent_id\"], \"h1n1_vaccine\": preds})\n",
        "            fname = f\"challenge_submission_groupB_order{rank}_{mname}_F1_{r['F1_valid']:.4f}.csv\"\n",
        "            sub.to_csv(os.path.join(\"submissions\", fname), index=False)\n",
        "            print(\"Saved:\", fname)\n",
        "            continue\n",
        "\n",
        "        # normalize & threshold using validation-optimal threshold for that model\n",
        "        s_min, s_max = s.min(), s.max()\n",
        "        s_norm = (s - s_min) / (s_max - s_min + 1e-9)\n",
        "        preds = (s_norm >= r[\"threshold\"]).astype(int)\n",
        "\n",
        "        sub = pd.DataFrame({\"respondent_id\": test[\"respondent_id\"], \"h1n1_vaccine\": preds})\n",
        "        fname = f\"challenge_submission_groupB_order{rank}_{mname}_F1_{r['F1_valid']:.4f}.csv\"\n",
        "        sub.to_csv(os.path.join(\"submissions\", fname), index=False)\n",
        "        print(\"Saved:\", fname)\n",
        "else:\n",
        "    print(\"\\nNo testing CSV found — training/validation complete. (This matches your professor’s plan.)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 936
        },
        "id": "0yA1RDLRsEfG",
        "outputId": "21b10710-0492-4ce2-8890-95d508a032bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training: logreg\n",
            " -> F1=0.6903 | P=0.6040 | R=0.8053 | Acc=0.7153\n",
            "Training: rf\n",
            " -> F1=0.6792 | P=0.6385 | R=0.7253 | Acc=0.7300\n",
            "Training: hgb\n",
            " -> F1=0.6782 | P=0.6307 | R=0.7333 | Acc=0.7258\n",
            "Training: extra\n",
            " -> F1=0.6775 | P=0.6355 | R=0.7253 | Acc=0.7279\n",
            "Training: linsvc_cal\n",
            " -> F1=0.6850 | P=0.6217 | R=0.7627 | Acc=0.7237\n",
            "Training: xgb\n",
            " -> F1=0.6732 | P=0.6261 | R=0.7280 | Acc=0.7216\n",
            "Training: lgbm\n",
            "[LightGBM] [Info] Number of positive: 1499, number of negative: 2305\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001036 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 149\n",
            "[LightGBM] [Info] Number of data points in the train set: 3804, number of used features: 65\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            " -> F1=0.6744 | P=0.5979 | R=0.7733 | Acc=0.7059\n",
            "Training: cat\n",
            " -> F1=0.6688 | P=0.5556 | R=0.8400 | Acc=0.6723\n",
            "Training: gbc\n",
            " -> F1=0.6918 | P=0.6368 | R=0.7573 | Acc=0.7342\n",
            "Training: dt\n",
            " -> F1=0.5800 | P=0.5660 | R=0.5947 | Acc=0.6607\n",
            "\n",
            "=== Leaderboard (Validation) ===\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7bcfb3d90110>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_f65e8_row0_col1, #T_f65e8_row1_col4, #T_f65e8_row2_col1, #T_f65e8_row2_col5, #T_f65e8_row4_col1, #T_f65e8_row7_col1 {\n",
              "  background-color: #0b559f;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f65e8_row0_col2, #T_f65e8_row0_col5, #T_f65e8_row1_col1, #T_f65e8_row3_col1, #T_f65e8_row3_col3, #T_f65e8_row5_col1, #T_f65e8_row8_col4 {\n",
              "  background-color: #08306b;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f65e8_row0_col3 {\n",
              "  background-color: #083573;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f65e8_row0_col4 {\n",
              "  background-color: #3888c1;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f65e8_row1_col2 {\n",
              "  background-color: #083370;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f65e8_row1_col3 {\n",
              "  background-color: #4f9bcb;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f65e8_row1_col5 {\n",
              "  background-color: #2272b6;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f65e8_row2_col2 {\n",
              "  background-color: #084082;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f65e8_row2_col3 {\n",
              "  background-color: #1764ab;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f65e8_row2_col4 {\n",
              "  background-color: #3282be;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f65e8_row3_col2, #T_f65e8_row4_col5 {\n",
              "  background-color: #084e98;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f65e8_row3_col4, #T_f65e8_row5_col4 {\n",
              "  background-color: #60a7d2;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f65e8_row3_col5 {\n",
              "  background-color: #083e81;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f65e8_row4_col2 {\n",
              "  background-color: #08509b;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f65e8_row4_col3 {\n",
              "  background-color: #08488e;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f65e8_row4_col4 {\n",
              "  background-color: #56a0ce;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f65e8_row5_col2 {\n",
              "  background-color: #08519c;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f65e8_row5_col3 {\n",
              "  background-color: #083979;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f65e8_row5_col5 {\n",
              "  background-color: #08468b;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f65e8_row6_col1 {\n",
              "  background-color: #539ecd;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f65e8_row6_col2 {\n",
              "  background-color: #0e58a2;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f65e8_row6_col3 {\n",
              "  background-color: #68acd5;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f65e8_row6_col4 {\n",
              "  background-color: #2676b8;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f65e8_row6_col5 {\n",
              "  background-color: #4594c7;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f65e8_row7_col2 {\n",
              "  background-color: #105ba4;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f65e8_row7_col3 {\n",
              "  background-color: #0d57a1;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f65e8_row7_col4 {\n",
              "  background-color: #5ca4d0;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f65e8_row7_col5 {\n",
              "  background-color: #115ca5;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f65e8_row8_col1 {\n",
              "  background-color: #89bedc;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_f65e8_row8_col2 {\n",
              "  background-color: #1865ac;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f65e8_row8_col3, #T_f65e8_row9_col1, #T_f65e8_row9_col2, #T_f65e8_row9_col4, #T_f65e8_row9_col5 {\n",
              "  background-color: #f7fbff;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_f65e8_row8_col5 {\n",
              "  background-color: #d8e7f5;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_f65e8_row9_col3 {\n",
              "  background-color: #deebf7;\n",
              "  color: #000000;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_f65e8\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_f65e8_level0_col0\" class=\"col_heading level0 col0\" >name</th>\n",
              "      <th id=\"T_f65e8_level0_col1\" class=\"col_heading level0 col1\" >threshold</th>\n",
              "      <th id=\"T_f65e8_level0_col2\" class=\"col_heading level0 col2\" >F1_valid</th>\n",
              "      <th id=\"T_f65e8_level0_col3\" class=\"col_heading level0 col3\" >precision</th>\n",
              "      <th id=\"T_f65e8_level0_col4\" class=\"col_heading level0 col4\" >recall</th>\n",
              "      <th id=\"T_f65e8_level0_col5\" class=\"col_heading level0 col5\" >accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_f65e8_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_f65e8_row0_col0\" class=\"data row0 col0\" >gbc</td>\n",
              "      <td id=\"T_f65e8_row0_col1\" class=\"data row0 col1\" >0.350000</td>\n",
              "      <td id=\"T_f65e8_row0_col2\" class=\"data row0 col2\" >0.691839</td>\n",
              "      <td id=\"T_f65e8_row0_col3\" class=\"data row0 col3\" >0.636771</td>\n",
              "      <td id=\"T_f65e8_row0_col4\" class=\"data row0 col4\" >0.757333</td>\n",
              "      <td id=\"T_f65e8_row0_col5\" class=\"data row0 col5\" >0.734244</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_f65e8_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "      <td id=\"T_f65e8_row1_col0\" class=\"data row1 col0\" >logreg</td>\n",
              "      <td id=\"T_f65e8_row1_col1\" class=\"data row1 col1\" >0.400000</td>\n",
              "      <td id=\"T_f65e8_row1_col2\" class=\"data row1 col2\" >0.690286</td>\n",
              "      <td id=\"T_f65e8_row1_col3\" class=\"data row1 col3\" >0.604000</td>\n",
              "      <td id=\"T_f65e8_row1_col4\" class=\"data row1 col4\" >0.805333</td>\n",
              "      <td id=\"T_f65e8_row1_col5\" class=\"data row1 col5\" >0.715336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_f65e8_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "      <td id=\"T_f65e8_row2_col0\" class=\"data row2 col0\" >linsvc_cal</td>\n",
              "      <td id=\"T_f65e8_row2_col1\" class=\"data row2 col1\" >0.350000</td>\n",
              "      <td id=\"T_f65e8_row2_col2\" class=\"data row2 col2\" >0.685030</td>\n",
              "      <td id=\"T_f65e8_row2_col3\" class=\"data row2 col3\" >0.621739</td>\n",
              "      <td id=\"T_f65e8_row2_col4\" class=\"data row2 col4\" >0.762667</td>\n",
              "      <td id=\"T_f65e8_row2_col5\" class=\"data row2 col5\" >0.723739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_f65e8_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "      <td id=\"T_f65e8_row3_col0\" class=\"data row3 col0\" >rf</td>\n",
              "      <td id=\"T_f65e8_row3_col1\" class=\"data row3 col1\" >0.400000</td>\n",
              "      <td id=\"T_f65e8_row3_col2\" class=\"data row3 col2\" >0.679151</td>\n",
              "      <td id=\"T_f65e8_row3_col3\" class=\"data row3 col3\" >0.638498</td>\n",
              "      <td id=\"T_f65e8_row3_col4\" class=\"data row3 col4\" >0.725333</td>\n",
              "      <td id=\"T_f65e8_row3_col5\" class=\"data row3 col5\" >0.730042</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_f65e8_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "      <td id=\"T_f65e8_row4_col0\" class=\"data row4 col0\" >hgb</td>\n",
              "      <td id=\"T_f65e8_row4_col1\" class=\"data row4 col1\" >0.350000</td>\n",
              "      <td id=\"T_f65e8_row4_col2\" class=\"data row4 col2\" >0.678175</td>\n",
              "      <td id=\"T_f65e8_row4_col3\" class=\"data row4 col3\" >0.630734</td>\n",
              "      <td id=\"T_f65e8_row4_col4\" class=\"data row4 col4\" >0.733333</td>\n",
              "      <td id=\"T_f65e8_row4_col5\" class=\"data row4 col5\" >0.725840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_f65e8_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
              "      <td id=\"T_f65e8_row5_col0\" class=\"data row5 col0\" >extra</td>\n",
              "      <td id=\"T_f65e8_row5_col1\" class=\"data row5 col1\" >0.400000</td>\n",
              "      <td id=\"T_f65e8_row5_col2\" class=\"data row5 col2\" >0.677460</td>\n",
              "      <td id=\"T_f65e8_row5_col3\" class=\"data row5 col3\" >0.635514</td>\n",
              "      <td id=\"T_f65e8_row5_col4\" class=\"data row5 col4\" >0.725333</td>\n",
              "      <td id=\"T_f65e8_row5_col5\" class=\"data row5 col5\" >0.727941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_f65e8_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
              "      <td id=\"T_f65e8_row6_col0\" class=\"data row6 col0\" >lgbm</td>\n",
              "      <td id=\"T_f65e8_row6_col1\" class=\"data row6 col1\" >0.250000</td>\n",
              "      <td id=\"T_f65e8_row6_col2\" class=\"data row6 col2\" >0.674419</td>\n",
              "      <td id=\"T_f65e8_row6_col3\" class=\"data row6 col3\" >0.597938</td>\n",
              "      <td id=\"T_f65e8_row6_col4\" class=\"data row6 col4\" >0.773333</td>\n",
              "      <td id=\"T_f65e8_row6_col5\" class=\"data row6 col5\" >0.705882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_f65e8_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
              "      <td id=\"T_f65e8_row7_col0\" class=\"data row7 col0\" >xgb</td>\n",
              "      <td id=\"T_f65e8_row7_col1\" class=\"data row7 col1\" >0.350000</td>\n",
              "      <td id=\"T_f65e8_row7_col2\" class=\"data row7 col2\" >0.673243</td>\n",
              "      <td id=\"T_f65e8_row7_col3\" class=\"data row7 col3\" >0.626147</td>\n",
              "      <td id=\"T_f65e8_row7_col4\" class=\"data row7 col4\" >0.728000</td>\n",
              "      <td id=\"T_f65e8_row7_col5\" class=\"data row7 col5\" >0.721639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_f65e8_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
              "      <td id=\"T_f65e8_row8_col0\" class=\"data row8 col0\" >cat</td>\n",
              "      <td id=\"T_f65e8_row8_col1\" class=\"data row8 col1\" >0.200000</td>\n",
              "      <td id=\"T_f65e8_row8_col2\" class=\"data row8 col2\" >0.668790</td>\n",
              "      <td id=\"T_f65e8_row8_col3\" class=\"data row8 col3\" >0.555556</td>\n",
              "      <td id=\"T_f65e8_row8_col4\" class=\"data row8 col4\" >0.840000</td>\n",
              "      <td id=\"T_f65e8_row8_col5\" class=\"data row8 col5\" >0.672269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_f65e8_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
              "      <td id=\"T_f65e8_row9_col0\" class=\"data row9 col0\" >dt</td>\n",
              "      <td id=\"T_f65e8_row9_col1\" class=\"data row9 col1\" >0.050000</td>\n",
              "      <td id=\"T_f65e8_row9_col2\" class=\"data row9 col2\" >0.579974</td>\n",
              "      <td id=\"T_f65e8_row9_col3\" class=\"data row9 col3\" >0.565990</td>\n",
              "      <td id=\"T_f65e8_row9_col4\" class=\"data row9 col4\" >0.594667</td>\n",
              "      <td id=\"T_f65e8_row9_col5\" class=\"data row9 col5\" >0.660714</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top model for tuning: gbc\n",
            "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33476cea",
        "outputId": "c8ee6c03-74f8-4485-f203-ae886110a4c2"
      },
      "source": [
        "%pip install catboost"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.12/dist-packages (from catboost) (0.21)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from catboost) (1.16.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (3.2.5)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly->catboost) (8.5.0)\n",
            "Downloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl (99.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87f6b81c"
      },
      "source": [
        "After installing the library, please re-run the previous cell to continue with the model training and evaluation."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I4pkYKevtVqp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}